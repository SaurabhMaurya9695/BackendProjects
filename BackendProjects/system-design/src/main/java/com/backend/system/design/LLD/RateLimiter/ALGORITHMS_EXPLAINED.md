# Rate Limiting Algorithms - Deep Dive Explanation

This document provides an in-depth explanation of how each rate limiting algorithm works, with step-by-step examples.

---

## ðŸ“š Table of Contents

1. [Token Bucket - Step by Step](#token-bucket---step-by-step)
2. [Leaky Bucket - Step by Step](#leaky-bucket---step-by-step)
3. [Fixed Window Counter - Step by Step](#fixed-window-counter---step-by-step)
4. [Sliding Window Log - Step by Step](#sliding-window-log---step-by-step)
5. [Sliding Window Counter - Step by Step](#sliding-window-counter---step-by-step)
6. [When to Use Which Algorithm](#when-to-use-which-algorithm)

---

## 1. Token Bucket - Step by Step

### ðŸŽ¯ Core Idea
Think of it like a **coin purse**:
- You start with some coins (tokens)
- Every second, new coins are added (refill rate)
- To make a purchase (request), you need 1 coin
- Maximum coins you can hold is limited (bucket capacity)

### ðŸ“– Step-by-Step Example

**Configuration:**
- Max Bucket Size: 5 tokens
- Refill Rate: 2 tokens/second
- Cost per request: 1 token

**Timeline:**

```
Time: 0:00
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Bucket: ðŸª™ ðŸª™ ðŸª™ ðŸª™ ðŸª™      â”‚  Tokens: 5/5
â”‚ Status: FULL               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User makes 3 requests:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Bucket: ðŸª™ ðŸª™              â”‚  Tokens: 2/5
â”‚ Status: 3 requests served  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Request 4: âœ“ ALLOWED (token consumed)
Request 5: âœ“ ALLOWED (token consumed)
Request 6: âœ— BLOCKED (no tokens left)

Time: 0:02 (2 seconds later)
Refill: +4 tokens (2 tokens/sec Ã— 2 sec)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Bucket: ðŸª™ ðŸª™ ðŸª™ ðŸª™         â”‚  Tokens: 4/5 (can't exceed max)
â”‚ Status: Refilled           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Request 7: âœ“ ALLOWED
Request 8: âœ“ ALLOWED
Request 9: âœ“ ALLOWED
Request 10: âœ“ ALLOWED
Request 11: âœ— BLOCKED
```

### ðŸ’» Code Walkthrough

```java
public boolean allowRequest(String userId) {
    long currentTime = System.currentTimeMillis();
    
    // Step 1: Get or create bucket for user
    Bucket bucket = userBuckets.computeIfAbsent(userId, 
        k -> new Bucket(maxBucketSize, currentTime));
    
    // Step 2: Calculate tokens to add
    long timeElapsed = currentTime - bucket.lastRefillTimestamp;  // milliseconds
    int tokensToAdd = (int) ((timeElapsed / 1000.0) * refillRate);
    
    // Step 3: Refill bucket (don't exceed max)
    if (tokensToAdd > 0) {
        bucket.tokens = Math.min(bucket.tokens + tokensToAdd, maxBucketSize);
        bucket.lastRefillTimestamp = currentTime;
    }
    
    // Step 4: Try to consume a token
    if (bucket.tokens > 0) {
        bucket.tokens--;
        return true;  // Request allowed
    }
    
    return false;  // Request blocked
}
```

### ðŸŽ“ Key Insights

1. **Burst Handling:** Can save up tokens for burst traffic
2. **Smooth Refill:** Tokens refill continuously, not in batches
3. **Memory Efficient:** Only stores token count and timestamp
4. **Use Case:** Perfect for APIs that allow occasional bursts (e.g., Stripe, AWS)

---

## 2. Leaky Bucket - Step by Step

### ðŸŽ¯ Core Idea
Imagine a **bucket with a hole**:
- Water (requests) pours in from the top
- Water leaks out at a constant rate from the bottom
- If bucket overflows, water (requests) are lost
- Bucket has a maximum capacity

### ðŸ“– Step-by-Step Example

**Configuration:**
- Bucket Capacity: 5 requests
- Leak Rate: 2 requests/second

**Timeline:**

```
Time: 0:00 (Empty bucket)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              â”‚  Queue: []
â”‚              â”‚  Size: 0/5
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“â†“ (leaking)

5 requests arrive instantly:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Request 5   â”‚
â”‚  Request 4   â”‚
â”‚  Request 3   â”‚  Queue: [R1, R2, R3, R4, R5]
â”‚  Request 2   â”‚  Size: 5/5 (FULL)
â”‚  Request 1   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“â†“
Request 6 arrives: âœ— BLOCKED (overflow!)

Time: 0:01 (1 second later)
Leaked: 2 requests processed
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              â”‚
â”‚              â”‚
â”‚  Request 5   â”‚  Queue: [R3, R4, R5]
â”‚  Request 4   â”‚  Size: 3/5
â”‚  Request 3   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“â†“
Request 6 arrives: âœ“ ALLOWED (space available)

Time: 0:02 (2 seconds later)
Leaked: 4 more requests processed
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              â”‚
â”‚              â”‚
â”‚              â”‚  Queue: [R6]
â”‚              â”‚  Size: 1/5
â”‚  Request 6   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“â†“
```

### ðŸ’» Code Walkthrough

```java
public boolean allowRequest(String userId) {
    long currentTime = System.currentTimeMillis();
    
    // Step 1: Get or create bucket for user
    Bucket bucket = userBuckets.computeIfAbsent(userId, 
        k -> new Bucket(currentTime));
    
    // Step 2: Calculate how many requests should leak
    long timeElapsed = currentTime - bucket.lastLeakTimestamp;
    int requestsToLeak = (int) ((timeElapsed / 1000.0) * leakRate);
    
    // Step 3: Remove (process) leaked requests
    for (int i = 0; i < requestsToLeak && !bucket.requestQueue.isEmpty(); i++) {
        bucket.requestQueue.poll();  // Remove oldest request
    }
    
    // Step 4: Update last leak time
    if (requestsToLeak > 0) {
        bucket.lastLeakTimestamp = currentTime;
    }
    
    // Step 5: Try to add new request
    if (bucket.requestQueue.size() < bucketCapacity) {
        bucket.requestQueue.offer(currentTime);
        return true;  // Request allowed
    }
    
    return false;  // Request blocked (overflow)
}
```

### ðŸŽ“ Key Insights

1. **Constant Output:** Processes requests at a fixed rate
2. **Smoothing:** Absorbs bursts and smooths them out
3. **Queue Required:** Needs to maintain a queue of requests
4. **Use Case:** Network packet scheduling, video streaming

---

## 3. Fixed Window Counter - Step by Step

### ðŸŽ¯ Core Idea
Imagine a **daily visitor counter**:
- Counter starts at 0 at the beginning of the day
- Each visitor increments the counter
- Maximum 100 visitors per day
- Counter resets at midnight
- Problem: 100 at 11:59 PM + 100 at 12:00 AM = 200 in 1 minute!

### ðŸ“– Step-by-Step Example

**Configuration:**
- Max Requests: 5
- Window Size: 60 seconds

**Timeline:**

```
Window 1: 0:00 - 1:00
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Time | Request | Counter | Status   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 0:10 â”‚    1    â”‚   1/5   â”‚ âœ“ ALLOW  â”‚
â”‚ 0:15 â”‚    2    â”‚   2/5   â”‚ âœ“ ALLOW  â”‚
â”‚ 0:20 â”‚    3    â”‚   3/5   â”‚ âœ“ ALLOW  â”‚
â”‚ 0:30 â”‚    4    â”‚   4/5   â”‚ âœ“ ALLOW  â”‚
â”‚ 0:40 â”‚    5    â”‚   5/5   â”‚ âœ“ ALLOW  â”‚
â”‚ 0:50 â”‚    6    â”‚   5/5   â”‚ âœ— BLOCK  â”‚
â”‚ 0:59 â”‚    7    â”‚   5/5   â”‚ âœ— BLOCK  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Window 2: 1:00 - 2:00 (Counter RESETS!)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Time | Request | Counter | Status   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1:00 â”‚    8    â”‚   1/5   â”‚ âœ“ ALLOW  â”‚
â”‚ 1:01 â”‚    9    â”‚   2/5   â”‚ âœ“ ALLOW  â”‚
â”‚ 1:02 â”‚   10    â”‚   3/5   â”‚ âœ“ ALLOW  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ðŸš¨ BOUNDARY PROBLEM:
Between 0:59 and 1:00 (1 second):
- At 0:59: Can send 5 requests (if counter was empty)
- At 1:00: Can send 5 requests (counter reset)
- Total: 10 requests in 1 second! (2x the limit)
```

### ðŸ’» Code Walkthrough

```java
public boolean allowRequest(String userId) {
    long currentTime = System.currentTimeMillis();
    
    // Step 1: Calculate current window start time
    // Example: If time is 1:30 and window is 60s, window starts at 1:00
    long currentWindowStart = (currentTime / windowSizeMs) * windowSizeMs;
    
    // Step 2: Get or create window for user
    Window window = userWindows.computeIfAbsent(userId, 
        k -> new Window(0, currentWindowStart));
    
    // Step 3: Check if we're in a new window
    if (window.windowStart != currentWindowStart) {
        // Reset counter for new window
        window.count = 0;
        window.windowStart = currentWindowStart;
    }
    
    // Step 4: Check if under limit
    if (window.count < maxRequests) {
        window.count++;
        return true;  // Request allowed
    }
    
    return false;  // Request blocked
}
```

### ðŸŽ“ Key Insights

1. **Simplest Algorithm:** Very easy to implement
2. **Memory Efficient:** Just one counter per user
3. **Boundary Problem:** Can allow 2x limit at window edges
4. **Use Case:** Simple APIs, quick MVPs, non-critical rate limiting

---

## 4. Sliding Window Log - Step by Step

### ðŸŽ¯ Core Idea
Think of a **rolling attendance sheet**:
- Keep timestamps of all attendees in the last hour
- For each new person, check timestamps
- Remove people who came more than 1 hour ago
- Count remaining people
- If count < limit, allow entry

### ðŸ“– Step-by-Step Example

**Configuration:**
- Max Requests: 3
- Window Size: 60 seconds

**Timeline:**

```
Current Time: 12:00:00
Log: []
Request 1 at 12:00:00: âœ“ ALLOWED
Log: [12:00:00]

Request 2 at 12:00:10: âœ“ ALLOWED
Log: [12:00:00, 12:00:10]

Request 3 at 12:00:20: âœ“ ALLOWED
Log: [12:00:00, 12:00:10, 12:00:20]

Request 4 at 12:00:30: âœ— BLOCKED (3 requests in window)
Log: [12:00:00, 12:00:10, 12:00:20]

Current Time: 12:00:50
Window Start: 11:59:50
Remove timestamps < 11:59:50:
Log: [12:00:00, 12:00:10, 12:00:20] (all still valid)

Current Time: 12:01:05
Window Start: 12:00:05
Remove timestamps < 12:00:05:
  - Remove 12:00:00 (too old)
Log: [12:00:10, 12:00:20] (2 requests remaining)

Request 5 at 12:01:05: âœ“ ALLOWED
Log: [12:00:10, 12:00:20, 12:01:05]

Request 6 at 12:01:10: âœ— BLOCKED
Log: [12:00:10, 12:00:20, 12:01:05]

Current Time: 12:01:15
Window Start: 12:00:15
Remove timestamps < 12:00:15:
  - Remove 12:00:10 (too old)
Log: [12:00:20, 12:01:05]

Request 7 at 12:01:15: âœ“ ALLOWED
Log: [12:00:20, 12:01:05, 12:01:15]
```

### ðŸ’» Code Walkthrough

```java
public boolean allowRequest(String userId) {
    long currentTime = System.currentTimeMillis();
    
    // Step 1: Calculate sliding window start
    long windowStart = currentTime - windowSizeMs;
    
    // Step 2: Get or create request log for user
    Queue<Long> requestLog = userRequestLogs.computeIfAbsent(userId, 
        k -> new LinkedList<>());
    
    // Step 3: Remove timestamps outside the window
    while (!requestLog.isEmpty() && requestLog.peek() <= windowStart) {
        requestLog.poll();  // Remove old timestamps
    }
    
    // Step 4: Check if under limit
    if (requestLog.size() < maxRequests) {
        requestLog.offer(currentTime);  // Add current timestamp
        return true;  // Request allowed
    }
    
    return false;  // Request blocked
}
```

### ðŸŽ“ Key Insights

1. **Most Accurate:** No boundary issues
2. **High Memory:** Stores every single timestamp
3. **Precise Control:** Perfect for critical applications
4. **Use Case:** Financial APIs, payment gateways, critical systems

**Memory Analysis:**
```
Users: 1,000,000
Limit: 1,000 requests/minute per user
Memory: 1M users Ã— 1K timestamps Ã— 8 bytes = 8 GB!
```

---

## 5. Sliding Window Counter - Step by Step

### ðŸŽ¯ Core Idea
**Best of both worlds:**
- Use two fixed windows (previous and current)
- Weight the previous window based on overlap
- More accurate than fixed window, less memory than log

### ðŸ“– Step-by-Step Example

**Configuration:**
- Max Requests: 10
- Window Size: 60 seconds

**Scenario:**

```
Timeline:
Previous Window     Current Window
    (60s)              (60s)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               â”‚               â”‚
â”‚  12:00-13:00  â”‚  13:00-14:00  â”‚
â”‚               â”‚       â†‘       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                  Current Time
                  13:00:45
                  (45s into window)

Previous Window (12:00-13:00): 8 requests
Current Window (13:00-14:00): 3 requests

Step 1: Calculate overlap percentage
- We're 45 seconds into current window
- Previous window overlap = (60 - 45) / 60 = 15 / 60 = 25%

Step 2: Calculate weighted count
Weighted Count = Current + (Previous Ã— Overlap%)
               = 3 + (8 Ã— 0.25)
               = 3 + 2
               = 5 requests

Step 3: Compare with limit
5 < 10 âœ“ ALLOW new request

After allowing request:
Current Window Count: 4
Weighted Count: 4 + (8 Ã— 0.25) = 6 requests
```

### ðŸ’» Code Walkthrough

```java
public boolean allowRequest(String userId) {
    long currentTime = System.currentTimeMillis();
    
    // Step 1: Calculate current window start
    long currentWindowStart = (currentTime / windowSizeMs) * windowSizeMs;
    
    // Step 2: Get or create window data
    WindowData windowData = userWindows.computeIfAbsent(userId, 
        k -> new WindowData(0, 0, currentWindowStart));
    
    // Step 3: Check if we moved to a new window
    if (windowData.currentWindowStart != currentWindowStart) {
        // Slide window: current â†’ previous
        windowData.previousWindowCount = windowData.currentWindowCount;
        windowData.currentWindowCount = 0;
        windowData.currentWindowStart = currentWindowStart;
    }
    
    // Step 4: Calculate time into current window
    long timeIntoCurrentWindow = currentTime - currentWindowStart;
    
    // Step 5: Calculate overlap percentage
    // How much of the previous window overlaps with our sliding window?
    double overlapPercentage = (windowSizeMs - timeIntoCurrentWindow) 
                               / (double) windowSizeMs;
    
    // Step 6: Calculate weighted count
    double weightedCount = windowData.currentWindowCount + 
                          (windowData.previousWindowCount * overlapPercentage);
    
    // Step 7: Check if under limit
    if (weightedCount < maxRequests) {
        windowData.currentWindowCount++;
        return true;  // Request allowed
    }
    
    return false;  // Request blocked
}
```

### ðŸ“Š Visual Formula Breakdown

```
Let's say:
- Window Size = 60 seconds
- Limit = 100 requests
- Current Time = 45 seconds into window

     Previous Window          Current Window
     (0-60s)                  (60-120s)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â† 15s overlap â†’â”‚                     â”‚
â”‚ 80 requests     â”‚ 30 requests         â”‚
â”‚                 â”‚         â†‘           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                         Current Time (105s)
                         45s into window

Overlap = 15s / 60s = 0.25 (25%)

Weighted = 30 + (80 Ã— 0.25)
         = 30 + 20
         = 50 requests

50 < 100 âœ“ Request ALLOWED
```

### ðŸŽ“ Key Insights

1. **Balanced Approach:** Better than fixed window, efficient than log
2. **Production Ready:** Used by Cloudflare, Kong
3. **Good Approximation:** ~95% accuracy in practice
4. **Use Case:** High-traffic production APIs

---

## 6. When to Use Which Algorithm

### Decision Matrix

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ALGORITHM SELECTOR                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  Need to handle bursts?                                        â”‚
â”‚  â”Œâ”€ YES â†’ Token Bucket                                         â”‚
â”‚  â””â”€ NO  â†’ Continue                                             â”‚
â”‚                                                                â”‚
â”‚  Need constant output rate?                                    â”‚
â”‚  â”Œâ”€ YES â†’ Leaky Bucket                                         â”‚
â”‚  â””â”€ NO  â†’ Continue                                             â”‚
â”‚                                                                â”‚
â”‚  Need 100% accuracy?                                           â”‚
â”‚  â”Œâ”€ YES â†’ Can handle memory? â†’ YES â†’ Sliding Window Log       â”‚
â”‚  â”‚                           â†’ NO  â†’ Sliding Window Counter    â”‚
â”‚  â””â”€ NO  â†’ Continue                                             â”‚
â”‚                                                                â”‚
â”‚  Simple MVP / prototype?                                       â”‚
â”‚  â”Œâ”€ YES â†’ Fixed Window Counter                                â”‚
â”‚  â””â”€ NO  â†’ Sliding Window Counter (default choice)             â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Use Case Table

| Scenario | Best Algorithm | Reason |
|----------|----------------|--------|
| **Social Media API** | Token Bucket | Allows burst of posts/likes |
| **Payment Gateway** | Sliding Window Log | Accuracy is critical |
| **Video Streaming** | Leaky Bucket | Constant bitrate needed |
| **Public API** | Sliding Window Counter | Balance of all factors |
| **Internal Microservice** | Fixed Window | Simple, low overhead |
| **DDoS Protection** | Token Bucket | Fast burst detection |
| **Database Queries** | Leaky Bucket | Smooth query rate |
| **Newsletter Service** | Fixed Window | Simple daily/hourly limits |
| **Financial Transactions** | Sliding Window Log | Regulatory compliance |
| **CDN Rate Limiting** | Sliding Window Counter | High scale, good accuracy |

---

## ðŸŽ“ Summary

### Quick Reference

```
Token Bucket â”€â”€â”€â”€â”€â–º Best for: APIs allowing bursts
    â””â”€ Memory: â­â­â­â­â­ (Low)
    â””â”€ Accuracy: â­â­â­â­ (Good)
    â””â”€ Examples: AWS, Stripe, GitHub

Leaky Bucket â”€â”€â”€â”€â”€â–º Best for: Constant output rate
    â””â”€ Memory: â­â­â­ (Medium)
    â””â”€ Accuracy: â­â­â­â­â­ (Perfect)
    â””â”€ Examples: Network QoS, Video streaming

Fixed Window â”€â”€â”€â”€â”€â–º Best for: Simple cases
    â””â”€ Memory: â­â­â­â­â­ (Lowest)
    â””â”€ Accuracy: â­â­ (Poor at boundaries)
    â””â”€ Examples: Simple APIs, Prototypes

Sliding Log â”€â”€â”€â”€â”€â”€â–º Best for: Critical accuracy
    â””â”€ Memory: â­ (Highest)
    â””â”€ Accuracy: â­â­â­â­â­ (Perfect)
    â””â”€ Examples: Payments, Financial

Sliding Counter â”€â”€â–º Best for: Production APIs
    â””â”€ Memory: â­â­â­â­ (Low)
    â””â”€ Accuracy: â­â­â­â­ (Very Good)
    â””â”€ Examples: Cloudflare, Kong, Production
```

### Learning Path

1. **Start:** Understand Fixed Window (simplest concept)
2. **Then:** Learn Token Bucket (refill logic)
3. **Next:** Study Sliding Window Log (precision)
4. **Finally:** Master Sliding Window Counter (production-ready)
5. **Advanced:** Leaky Bucket (specialized use cases)

---

**Happy Learning! ðŸš€**

Remember: The best algorithm depends on your specific requirements. There's no one-size-fits-all solution!

